{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**Srinivas Naidu Pasyavula <br>\n",
        "QC61851**\n",
        "<br><br>\n",
        "Dr. Tony Diana <br>\n",
        "DATA 690 Introduction to NLP <br>\n",
        "Homework, Week 7<br><br>\n",
        "Exercise 4. Sentiment analysis with spaCy."
      ],
      "metadata": {
        "id": "YezFikosVOzl"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k1aCRAS_VGhA",
        "outputId": "21ef3067-26a9-4026-f81d-8ce7fc274844"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "/content/drive/MyDrive/Colab Notebooks/NLP DATA 690 UMBC/Week7/Exercise 4\n",
            " amazon_cells_labelled.txt\t\t\t\t\t     Sentiment_Analysis_Dataset.csv\n",
            " imdb_labelled.txt\t\t\t\t\t\t     yelp_labelled.txt\n",
            "'QC61851-Srinivas Naidu Pasyavula-NLP-Week 7-Exercise 4- HW.ipynb'\n"
          ]
        }
      ],
      "source": [
        "# This code mounts your Google Drive to the Colab notebook, changes the directory to a specific folder on your Drive, and lists the contents of that folder using the ls command.\n",
        "\n",
        "#!hostname -I\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "#\n",
        "%cd /content/drive/MyDrive/'Colab Notebooks'/'NLP DATA 690 UMBC'/'Week7'/'Exercise 4'\n",
        "!ls"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# importing required libraries and packages\n",
        "import pandas as pd\n",
        "\n",
        "import spacy\n",
        "from spacy.lang.en.stop_words import STOP_WORDS\n",
        "import string\n",
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.svm import LinearSVC\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.base import TransformerMixin\n",
        "from sklearn.pipeline import Pipeline"
      ],
      "metadata": {
        "id": "vVOgfWZfXH6Y"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load datasets\n",
        "data_amazon = pd.read_csv('amazon_cells_labelled.txt', sep='\\t', header=None)\n",
        "data_imdb = pd.read_csv('imdb_labelled.txt', sep='\\t', header=None)\n",
        "data_yelp = pd.read_csv('yelp_labelled.txt', sep='\\t', header=None)"
      ],
      "metadata": {
        "id": "ivozL46hXPlc"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create combined dataframe\n",
        "data_amazon.columns = ['Review', 'Label']\n",
        "data_imdb.columns = ['Review', 'Label']\n",
        "data_yelp.columns = ['Review', 'Label']\n",
        "\n",
        "data_amazon['Company'] = 'Amazon'\n",
        "data_imdb['Company'] = 'IMDb'\n",
        "data_yelp['Company'] = 'Yelp'\n",
        "\n",
        "combined_col = pd.concat([data_amazon, data_imdb, data_yelp], ignore_index=True)"
      ],
      "metadata": {
        "id": "8UOdLnfxXS_z"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Explore the structure of the combined dataset\n",
        "print(combined_col.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4sbsXGMhXcKK",
        "outputId": "a5411dad-f6ca-4a57-8e1c-f33ebc43fb41"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                              Review  Label Company\n",
            "0  So there is no way for me to plug it in here i...      0  Amazon\n",
            "1                        Good case, Excellent value.      1  Amazon\n",
            "2                             Great for the jawbone.      1  Amazon\n",
            "3  Tied to charger for conversations lasting more...      0  Amazon\n",
            "4                                  The mic is great.      1  Amazon\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# infoof the data\n",
        "print(combined_col.info())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y-2-QAYxXxCd",
        "outputId": "3002b732-30ad-4d4e-a9ec-26a0c669cf9d"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 2748 entries, 0 to 2747\n",
            "Data columns (total 3 columns):\n",
            " #   Column   Non-Null Count  Dtype \n",
            "---  ------   --------------  ----- \n",
            " 0   Review   2748 non-null   object\n",
            " 1   Label    2748 non-null   int64 \n",
            " 2   Company  2748 non-null   object\n",
            "dtypes: int64(1), object(2)\n",
            "memory usage: 64.5+ KB\n",
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the combined dataset to a CSV file\n",
        "combined_col.to_csv('Sentiment_Analysis_Dataset.csv', index=False)"
      ],
      "metadata": {
        "id": "cg-S6_VpVX5p"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the English language model in spaCy\n",
        "nlp = spacy.load(\"en_core_web_sm\")"
      ],
      "metadata": {
        "id": "7JStkoTBX8sr"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Class to clean the text\n",
        "class predictors(TransformerMixin):\n",
        "    def transform(self, X, **transform_params):\n",
        "        return [text_preprocessor(text) for text in X]\n",
        "\n",
        "    def fit(self, X, y=None, **fit_params):\n",
        "        return self\n",
        "\n",
        "    def get_params(self, deep=True):\n",
        "        return {}"
      ],
      "metadata": {
        "id": "zHAdllDOX-j6"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# function to clean the text\n",
        "def text_preprocessor(text):\n",
        "    # Lowercase the text\n",
        "    text = text.lower()\n",
        "    return text"
      ],
      "metadata": {
        "id": "dFKU42D1YAfk"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Tokenizing sentences\n",
        "def spacy_tokenizer(sentence):\n",
        "    tokens = nlp(sentence)\n",
        "    tokens = [token.lemma_ for token in tokens if token.text.lower() not in STOP_WORDS and token.text not in string.punctuation]\n",
        "    return tokens"
      ],
      "metadata": {
        "id": "5NispzJ7YIxa"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Vectorize and use LinearSVC as a classifier\n",
        "pipe_countvect = Pipeline([\n",
        "    ('cleaner', predictors()),\n",
        "    # ('vectorizer', CountVectorizer(tokenizer=spacy_tokenizer, ngram_range=(1, 1))),\n",
        "    ('vectorizer', CountVectorizer(tokenizer=spacy_tokenizer, token_pattern=None, ngram_range=(1, 1))),\n",
        "    ('classifier', LinearSVC())])"
      ],
      "metadata": {
        "id": "wMT6OLRWYKJc"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Split the dataset into train and test sets\n",
        "X = combined_col['Review']\n",
        "y = combined_col['Label']\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "AZUiJjizYOjz"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Fit the data\n",
        "pipe_countvect.fit(X_train, y_train)\n",
        "\n",
        "# Predict with the test dataset\n",
        "y_pred = pipe_countvect.predict(X_test)"
      ],
      "metadata": {
        "id": "WBfRPa3RYSxk"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Print sample prediction results\n",
        "for sample, pred in zip(X_test[:5], y_pred[:5]):\n",
        "    print(f\"Sample: {sample} Prediction: {pred}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Htto9MTBWdvk",
        "outputId": "0cd12bdd-24cb-4fe3-9b09-b27f78ced41d"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample: It's close to my house, it's low-key, non-fancy, affordable prices, good food. Prediction: 1\n",
            "Sample: If you stay in Vegas you must get breakfast here at least once. Prediction: 1\n",
            "Sample: Let's start with all the problemsÂ—the acting, especially from the lead professor, was very, very bad.   Prediction: 0\n",
            "Sample: It's too bad that everyone else involved didn't share Crowe's level of dedication to quality, for if they did, we'd have a far better film on our hands than this sub-par mess.   Prediction: 0\n",
            "Sample: i felt insulted and disrespected, how could you talk and judge another human being like that? Prediction: 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate accuracy\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f\"Accuracy: {accuracy}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OVdSJpN1WiDP",
        "outputId": "1ad0bb23-5c73-44ae-d649-676a67b0c96c"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.8145454545454546\n"
          ]
        }
      ]
    }
  ]
}